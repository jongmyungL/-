import os
import re
import uuid
from datetime import datetime, timedelta
from html import unescape
from io import BytesIO
from typing import Dict, List, Tuple
from urllib.parse import urlparse

import pandas as pd
import requests
import streamlit as st
from dotenv import load_dotenv
from streamlit_autorefresh import st_autorefresh


st.set_page_config(
    page_title="PR-Radar | ìì‚¬ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§",
    page_icon="ğŸ›°ï¸",
    layout="wide",
)


NEGATIVE_KEYWORDS = ["ë…¼ë€", "ì†Œì†¡", "êµ¬ì„¤", "ë¶ˆë§¤", "ê°‘ì§ˆ", "ì‚¬ê³¼ë¬¸"]
PRESS_NAME_MAP = {
    "yna": "ì—°í•©ë‰´ìŠ¤",
    "yonhap": "ì—°í•©ë‰´ìŠ¤",
    "mk": "ë§¤ì¼ê²½ì œ",
    "hankyung": "í•œêµ­ê²½ì œ",
    "mt": "ë¨¸ë‹ˆíˆ¬ë°ì´",
    "sedaily": "ì„œìš¸ê²½ì œ",
    "etnews": "ì „ìì‹ ë¬¸",
    "heraldcorp": "í—¤ëŸ´ë“œê²½ì œ",
    "chosunbiz": "ì¡°ì„ ë¹„ì¦ˆ",
    "asiae": "ì•„ì‹œì•„ê²½ì œ",
}


def parse_dt(value: str) -> datetime:
    return datetime.strptime(value, "%Y-%m-%d %H:%M")


def fmt_dt(value: datetime) -> str:
    return value.strftime("%Y-%m-%d %H:%M")


def make_article(
    title: str,
    press: str,
    published_at: datetime,
    link: str,
    summary: str,
    query_keyword: str,
) -> Dict:
    hit_keywords = [kw for kw in NEGATIVE_KEYWORDS if kw in title or kw in summary]
    return {
        "id": str(uuid.uuid4())[:8],
        "title": title,
        "press": press,
        "published_at": published_at,
        "link": link,
        "summary": summary,
        "query_keyword": query_keyword,
        "is_negative": len(hit_keywords) > 0,
        "negative_hits": ", ".join(hit_keywords) if hit_keywords else "",
        "collected_at": datetime.now(),
    }


def get_mock_articles() -> List[Dict]:
    now = datetime.now()
    samples = [
        make_article(
            "OOí…Œí¬, ì‹ ì œí’ˆ ì¶œì‹œë¡œ í•´ì™¸ ì‹œì¥ ê³µëµ ë³¸ê²©í™”",
            "ë§¤ì¼ê²½ì œ",
            now - timedelta(hours=1),
            "https://example.com/news/1",
            "OOí…Œí¬ê°€ AI ê¸°ë°˜ ì‹ ì œí’ˆì„ ê³µê°œí•˜ë©° ê¸€ë¡œë²Œ í™•ì¥ ì „ëµì„ ë°œí‘œí–ˆë‹¤.",
            "OOí…Œí¬",
        ),
        make_article(
            "OOí…Œí¬ ì„ì› ì¸í„°ë·°: \"ì˜¬í•´ ë§¤ì¶œ 2ë°° ëª©í‘œ\"",
            "í•œêµ­ê²½ì œ",
            now - timedelta(hours=3),
            "https://example.com/news/2",
            "í•µì‹¬ ì„ì›ì´ ì‚¬ì—… ê³„íšê³¼ ì‹ ê·œ íˆ¬ì ë°©í–¥ì„ ì„¤ëª…í–ˆë‹¤.",
            "í™ê¸¸ë™",
        ),
        make_article(
            "OOí…Œí¬ í˜‘ë ¥ì‚¬ì™€ ì†Œì†¡ ê°€ëŠ¥ì„± ì œê¸°... ì—…ê³„ ê¸´ì¥",
            "ë¨¸ë‹ˆíˆ¬ë°ì´",
            now - timedelta(hours=5),
            "https://example.com/news/3",
            "ê³„ì•½ í•´ì„ì„ ë‘˜ëŸ¬ì‹¼ ê°ˆë“±ìœ¼ë¡œ ì†Œì†¡ ê°€ëŠ¥ì„±ì´ ì–¸ê¸‰ëë‹¤.",
            "OOí…Œí¬",
        ),
        make_article(
            "ì†Œë¹„ì ì»¤ë®¤ë‹ˆí‹°ì„œ OOí…Œí¬ ì„œë¹„ìŠ¤ í’ˆì§ˆ ë…¼ë€ í™•ì‚°",
            "ì—°í•©ë‰´ìŠ¤",
            now - timedelta(hours=7),
            "https://example.com/news/4",
            "ì¼ë¶€ ì‚¬ìš©ì ë¶ˆë§Œì´ ì»¤ë®¤ë‹ˆí‹°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¹ ë¥´ê²Œ í™•ì‚° ì¤‘ì´ë‹¤.",
            "OOí…Œí¬",
        ),
        make_article(
            "OOí…Œí¬, ëŒ€í•™ê³¼ ì‚°í•™ í˜‘ë ¥ í”„ë¡œì íŠ¸ ì¶”ì§„",
            "ì „ìì‹ ë¬¸",
            now - timedelta(days=1, hours=2),
            "https://example.com/news/5",
            "ì¸ì¬ ì–‘ì„±ê³¼ ì—°êµ¬ê°œë°œ í˜‘ë ¥ì„ ìœ„í•œ ì¥ê¸° í”„ë¡œê·¸ë¨ì´ ì‹œì‘ëë‹¤.",
            "OOí…Œí¬",
        ),
        make_article(
            "OOí…Œí¬, ì§€ì†ê°€ëŠ¥ê²½ì˜ ë³´ê³ ì„œ ê³µê°œ",
            "ì„œìš¸ê²½ì œ",
            now - timedelta(days=2),
            "https://example.com/news/6",
            "í™˜ê²½Â·ì‚¬íšŒÂ·ì§€ë°°êµ¬ì¡° ì„±ê³¼ë¥¼ ë‹´ì€ ë³´ê³ ì„œë¥¼ ë°œí‘œí–ˆë‹¤.",
            "OOí…Œí¬",
        ),
        make_article(
            "OOí…Œí¬ ê´€ë ¨ êµ¬ì„¤ í•´ëª…... ê³µì‹ ì‚¬ê³¼ë¬¸ ê²Œì¬",
            "ì¡°ì„ ë¹„ì¦ˆ",
            now - timedelta(days=3, hours=4),
            "https://example.com/news/7",
            "íšŒì‚¬ ì¸¡ì€ ì‚¬ì‹¤ê´€ê³„ë¥¼ ì„¤ëª…í•˜ê³  ì¬ë°œ ë°©ì§€ì±…ì„ ë°í˜”ë‹¤.",
            "OOí…Œí¬",
        ),
        make_article(
            "OOí…Œí¬, ì‹ ì… ê³µê°œì±„ìš© ì‹œì‘",
            "í—¤ëŸ´ë“œê²½ì œ",
            now - timedelta(days=6, hours=1),
            "https://example.com/news/8",
            "ê°œë°œÂ·ê¸°íš ë“± ì—¬ëŸ¬ ì§êµ°ì—ì„œ ëŒ€ê·œëª¨ ì±„ìš©ì„ ì§„í–‰í•œë‹¤.",
            "OOí…Œí¬",
        ),
    ]
    return samples


def init_state() -> None:
    if "keywords" not in st.session_state:
        st.session_state.keywords = ["ì‚¼ì„±í™”ì¬"]

    if "folders" not in st.session_state:
        st.session_state.folders = ["ë³´ë„ìë£Œ", "ê¸°íšê¸°ì‚¬", "ìœ„ê¸°ê´€ë¦¬", "ê²½ìŸì‚¬ ë™í–¥"]

    if "inbox_articles" not in st.session_state:
        st.session_state.inbox_articles = []

    if "saved_articles" not in st.session_state:
        st.session_state.saved_articles = []

    if "correction_items" not in st.session_state:
        st.session_state.correction_items = []

    if "alerts" not in st.session_state:
        st.session_state.alerts = []

    if "auto_collect_enabled" not in st.session_state:
        st.session_state.auto_collect_enabled = True

    if "last_auto_collect_at" not in st.session_state:
        st.session_state.last_auto_collect_at = datetime.now()


def purge_old_inbox(days: int = 7) -> None:
    threshold = datetime.now() - timedelta(days=days)
    st.session_state.inbox_articles = [
        a for a in st.session_state.inbox_articles if a["collected_at"] >= threshold
    ]


def refresh_alerts() -> None:
    items = []
    for article in st.session_state.inbox_articles:
        if article["is_negative"]:
            items.append(
                {
                    "time": article["published_at"],
                    "message": f"[ê²½ê³ ] ë¶€ì • í‚¤ì›Œë“œ({article['negative_hits']}) ê°ì§€ - {article['title']}",
                }
            )
    st.session_state.alerts = sorted(items, key=lambda x: x["time"], reverse=True)


def naver_api_ready() -> bool:
    load_dotenv()
    client_id = os.getenv("NAVER_CLIENT_ID", "")
    client_secret = os.getenv("NAVER_CLIENT_SECRET", "")
    return bool(client_id and client_secret)


def clean_html(text: str) -> str:
    no_tags = re.sub(r"<[^>]+>", "", text or "")
    return unescape(no_tags).strip()


def parse_naver_pub_date(value: str) -> datetime:
    # ì˜ˆ: "Thu, 26 Feb 2026 09:30:00 +0900"
    try:
        return datetime.strptime(value, "%a, %d %b %Y %H:%M:%S %z").replace(tzinfo=None)
    except ValueError:
        return datetime.now()


def guess_press_from_link(link: str) -> str:
    try:
        host = urlparse(link).netloc.lower().replace("www.", "")
        if not host:
            return "ì–¸ë¡ ì‚¬ ë¯¸ìƒ"
        parts = host.split(".")
        if len(parts) >= 2:
            return parts[-2]
        return host
    except Exception:
        return "ì–¸ë¡ ì‚¬ ë¯¸ìƒ"


def normalize_press_name(raw_press: str, link: str) -> str:
    value = (raw_press or "").strip()
    if value and re.search(r"[ê°€-í£]", value):
        return value

    lower_value = value.lower().replace(" ", "")
    for key, ko_name in PRESS_NAME_MAP.items():
        if key in lower_value:
            return ko_name

    host_guess = guess_press_from_link(link)
    lower_host_guess = host_guess.lower().replace(" ", "")
    for key, ko_name in PRESS_NAME_MAP.items():
        if key in lower_host_guess:
            return ko_name

    if value:
        return value
    return host_guess


def collect_news_from_naver() -> Tuple[int, str]:
    load_dotenv()
    client_id = os.getenv("NAVER_CLIENT_ID", "")
    client_secret = os.getenv("NAVER_CLIENT_SECRET", "")

    if not (client_id and client_secret):
        return 0, "no_key"

    endpoint = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret,
    }
    keywords = st.session_state.keywords or ["ì‚¼ì„±í™”ì¬"]
    existing_links = {a["link"] for a in st.session_state.inbox_articles}
    added = 0

    try:
        for keyword in keywords:
            params = {
                "query": keyword,
                "display": 20,
                "start": 1,
                "sort": "date",
            }
            response = requests.get(endpoint, headers=headers, params=params, timeout=10)
            response.raise_for_status()
            payload = response.json()
            items = payload.get("items", [])

            for item in items:
                link = item.get("originallink") or item.get("link") or ""
                if not link or link in existing_links:
                    continue

                title = clean_html(item.get("title", "ì œëª© ì—†ìŒ"))
                summary = clean_html(item.get("description", ""))
                press_raw = clean_html(item.get("source", ""))
                press = normalize_press_name(press_raw, link)
                published_at = parse_naver_pub_date(item.get("pubDate", ""))

                article = make_article(
                    title=title,
                    press=press,
                    published_at=published_at,
                    link=link,
                    summary=summary,
                    query_keyword=keyword,
                )
                st.session_state.inbox_articles.insert(0, article)
                existing_links.add(link)
                added += 1
        return added, "api"
    except requests.RequestException:
        return 0, "error"


def run_hourly_auto_collect() -> None:
    if not st.session_state.auto_collect_enabled:
        return
    if not naver_api_ready():
        return

    # ì•±ì´ ì—´ë ¤ ìˆëŠ” ë™ì•ˆ 1ë¶„ë§ˆë‹¤ ì²´í¬í•˜ê³ , 1ì‹œê°„ ê²½ê³¼ ì‹œ ìë™ ìˆ˜ì§‘ ì‹¤í–‰
    st_autorefresh(interval=60 * 1000, key="hourly_auto_collect_tick")
    now = datetime.now()
    if now - st.session_state.last_auto_collect_at >= timedelta(hours=1):
        added_count, source = collect_news_from_naver()
        refresh_alerts()
        st.session_state.last_auto_collect_at = now
        if source == "api":
            st.toast(f"ìë™ ìˆ˜ì§‘ ì™„ë£Œ: {added_count}ê±´", icon="â±ï¸")
        elif source == "error":
            st.toast("ìë™ ìˆ˜ì§‘ ì‹¤íŒ¨", icon="âš ï¸")


def to_excel_bytes(df: pd.DataFrame, sheet_name: str) -> bytes:
    output = BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df.to_excel(writer, sheet_name=sheet_name, index=False)
    output.seek(0)
    return output.read()


def draw_sidebar() -> str:
    st.sidebar.title("PR-Radar")
    st.sidebar.caption("ìì‚¬ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ ë° DB ìë™í™”")

    page = st.sidebar.radio(
        "ë©”ë‰´",
        [
            "ë©”ì¸ ëŒ€ì‹œë³´ë“œ",
            "ì„ì‹œ ë³´ê´€í•¨ (Inbox)",
            "ìŠ¤í¬ë© DB ë° í´ë” ê´€ë¦¬",
            "ê¸°ì‚¬ ìˆ˜ì • ìš”ì²­ ê´€ë¦¬",
        ],
    )

    st.sidebar.divider()
    with st.sidebar.expander("í‚¤ì›Œë“œ ì„¤ì •", expanded=False):
        st.caption("í´ë¦­í–ˆì„ ë•Œë§Œ í¼ì³ì§‘ë‹ˆë‹¤. ì—¬ëŸ¬ í‚¤ì›Œë“œë¥¼ ë“±ë¡í•´ ìˆ˜ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        new_keyword = st.text_input("ìƒˆ í‚¤ì›Œë“œ ì¶”ê°€", placeholder="ì˜ˆ: CEO ì´ë¦„")
        if st.button("í‚¤ì›Œë“œ ì¶”ê°€"):
            cleaned = new_keyword.strip()
            if not cleaned:
                st.warning("ì¶”ê°€í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            elif cleaned in st.session_state.keywords:
                st.warning("ì´ë¯¸ ë“±ë¡ëœ í‚¤ì›Œë“œì…ë‹ˆë‹¤.")
            else:
                st.session_state.keywords.append(cleaned)
                st.success(f"'{cleaned}' í‚¤ì›Œë“œë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")

        if st.session_state.keywords:
            st.write("#### ë“±ë¡ëœ í‚¤ì›Œë“œ (ì‚­ì œí•  í•­ëª© ì²´í¬)")
            checked_to_delete = []
            for kw in st.session_state.keywords:
                key = f"delete_kw_{kw}"
                is_checked = st.checkbox(kw, key=key)
                if is_checked:
                    checked_to_delete.append(kw)

            if st.button("ì²´í¬í•œ í‚¤ì›Œë“œ ì‚­ì œ"):
                if not checked_to_delete:
                    st.warning("ì‚­ì œí•  í‚¤ì›Œë“œë¥¼ ì²´í¬í•´ ì£¼ì„¸ìš”.")
                else:
                    st.session_state.keywords = [
                        kw for kw in st.session_state.keywords if kw not in checked_to_delete
                    ]
                    for kw in checked_to_delete:
                        st.session_state.pop(f"delete_kw_{kw}", None)
                    st.success(f"{len(checked_to_delete)}ê°œ í‚¤ì›Œë“œë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("ë“±ë¡ëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.sidebar.divider()
    if naver_api_ready():
        st.sidebar.success("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.sidebar.warning(
            "ë„¤ì´ë²„ API í‚¤ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.\n`.env`ì— NAVER_CLIENT_ID / NAVER_CLIENT_SECRETë¥¼ ì„¤ì •í•˜ì„¸ìš”."
        )

    if st.sidebar.button("ì§€ê¸ˆ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤í–‰"):
        added_count, source = collect_news_from_naver()
        refresh_alerts()
        if source == "api":
            st.sidebar.success(f"ìˆ˜ì§‘ ì™„ë£Œ: ë„¤ì´ë²„ API ê¸°ì‚¬ {added_count}ê±´ ì¶”ê°€")
        elif source == "no_key":
            st.sidebar.warning("API í‚¤ê°€ ì—†ì–´ ìˆ˜ì§‘ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `.env`ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        else:
            st.sidebar.warning("ë„¤ì´ë²„ API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    if st.sidebar.button("ì„ì‹œ ë³´ê´€í•¨ ë°ì´í„° ë¹„ìš°ê¸°"):
        st.session_state.inbox_articles = []
        st.session_state.alerts = []
        st.sidebar.success("ì„ì‹œ ë³´ê´€í•¨ì„ ë¹„ì› ìŠµë‹ˆë‹¤.")

    st.sidebar.divider()
    st.sidebar.write("### ìë™ ìˆ˜ì§‘ ì„¤ì •")
    st.session_state.auto_collect_enabled = st.sidebar.checkbox(
        "1ì‹œê°„ë§ˆë‹¤ ìë™ ìˆ˜ì§‘",
        value=st.session_state.auto_collect_enabled,
    )
    if st.session_state.auto_collect_enabled:
        st.sidebar.caption(f"ë§ˆì§€ë§‰ ìë™ ìˆ˜ì§‘: {fmt_dt(st.session_state.last_auto_collect_at)}")
    else:
        st.sidebar.caption("ìë™ ìˆ˜ì§‘ì´ êº¼ì ¸ ìˆìŠµë‹ˆë‹¤.")

    return page


def page_dashboard() -> None:
    st.title("ë©”ì¸ ëŒ€ì‹œë³´ë“œ")
    st.caption("ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ íë¦„ê³¼ ìœ„ê¸° ì‹ í˜¸ë¥¼ í•œëˆˆì— í™•ì¸í•˜ì„¸ìš”.")

    today = datetime.now().date()
    week_ago = datetime.now() - timedelta(days=7)

    collected_today = sum(
        1 for a in st.session_state.inbox_articles if a["published_at"].date() == today
    )
    scraped_this_week = sum(
        1 for a in st.session_state.saved_articles if a["saved_at"] >= week_ago
    )
    correction_in_progress = sum(
        1 for c in st.session_state.correction_items if c["status"] == "ìš”ì²­ë¨"
    )

    c1, c2, c3 = st.columns(3)
    c1.metric("ì˜¤ëŠ˜ ìˆ˜ì§‘ ê¸°ì‚¬ ìˆ˜", f"{collected_today}ê±´")
    c2.metric("ì´ë²ˆ ì£¼ ìŠ¤í¬ë© ê¸°ì‚¬ ìˆ˜", f"{scraped_this_week}ê±´")
    c3.metric("ìˆ˜ì • ìš”ì²­ ì¤‘", f"{correction_in_progress}ê±´")

    st.divider()
    left, right = st.columns([1, 1.2])

    with left:
        st.subheader("ìµœê·¼ ì•Œë¦¼")
        if not st.session_state.alerts:
            st.info("ë¶€ì • í‚¤ì›Œë“œ ê°ì§€ ì•Œë¦¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for alert in st.session_state.alerts[:5]:
                st.warning(f"{fmt_dt(alert['time'])} | {alert['message']}")

    with right:
        st.subheader("ìµœê·¼ ìˆ˜ì§‘ ê¸°ì‚¬")
        recent = sorted(
            st.session_state.inbox_articles,
            key=lambda x: x["published_at"],
            reverse=True,
        )[:5]
        if not recent:
            st.info("í‘œì‹œí•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for a in recent:
                neg_tag = " ğŸš¨" if a["is_negative"] else ""
                st.markdown(f"**[{a['title']}]({a['link']})**{neg_tag}")
                st.caption(f"{a['press']} | {fmt_dt(a['published_at'])} | í‚¤ì›Œë“œ: {a['query_keyword']}")


def page_inbox() -> None:
    st.title("ì„ì‹œ ë³´ê´€í•¨ (Inbox)")
    st.caption("ìˆ˜ì§‘ëœ ê¸°ì‚¬ë¥¼ í™•ì¸í•˜ê³  í•„ìš”í•œ ê¸°ì‚¬ë§Œ ì˜êµ¬ DBë¡œ ì €ì¥í•˜ì„¸ìš”. (7ì¼ í›„ ìë™ ì‚­ì œ)")

    if not st.session_state.inbox_articles:
        st.info("ì„ì‹œ ë³´ê´€í•¨ì— ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    target_folder = st.selectbox("ì €ì¥í•  ì„¹ì…˜(í´ë”) ì„ íƒ", st.session_state.folders)

    inbox_sorted = sorted(
        st.session_state.inbox_articles,
        key=lambda x: x["published_at"],
        reverse=True,
    )

    registered_keywords = [k for k in st.session_state.keywords if k.strip()]
    tab_labels = ["ì „ì²´"] + registered_keywords if registered_keywords else ["ì „ì²´"]
    tabs = st.tabs(tab_labels)

    for idx, (tab, label) in enumerate(zip(tabs, tab_labels)):
        with tab:
            if label == "ì „ì²´":
                filtered_articles = inbox_sorted
            else:
                filtered_articles = [a for a in inbox_sorted if a["query_keyword"] == label]

            if not filtered_articles:
                st.info(f"'{label}' í‚¤ì›Œë“œ ê¸°ì‚¬ ì—†ìŒ")
                continue

            table_data = [
                {
                    "ì„ íƒ": False,
                    "ì œëª©": a["title"],
                    "ì–¸ë¡ ì‚¬": normalize_press_name(a["press"], a["link"]),
                    "ì¼ì‹œ": fmt_dt(a["published_at"]),
                    "í‚¤ì›Œë“œ": a["query_keyword"],
                    "ë¶€ì •í‚¤ì›Œë“œ": a["negative_hits"],
                    "ê¸°ì‚¬ë§í¬": a["link"],
                    "_id": a["id"],
                }
                for a in filtered_articles
            ]
            df = pd.DataFrame(table_data)
            current_editor = st.data_editor(
                df,
                hide_index=True,
                use_container_width=True,
                disabled=["ì œëª©", "ì¼ì‹œ", "í‚¤ì›Œë“œ", "ë¶€ì •í‚¤ì›Œë“œ", "ê¸°ì‚¬ë§í¬", "_id"],
                column_config={
                    "_id": None,
                    "ì„ íƒ": st.column_config.CheckboxColumn("ì„ íƒ"),
                    "ì œëª©": st.column_config.TextColumn("ì œëª©", width="large"),
                    "ê¸°ì‚¬ë§í¬": st.column_config.LinkColumn(
                        "ê¸°ì‚¬ ë§í¬",
                    ),
                },
                key=f"inbox_editor_{idx}_{label}",
            )

            save_clicked = st.button(
                "ì„ íƒí•œ ê¸°ì‚¬ ì˜êµ¬ ì €ì¥í•˜ê¸°",
                type="primary",
                key=f"save_inbox_{idx}_{label}",
            )
            if save_clicked:
                selected_ids = current_editor.loc[current_editor["ì„ íƒ"] == True, "_id"].tolist()
                if not selected_ids:
                    st.warning("ì €ì¥í•  ê¸°ì‚¬ë¥¼ ë¨¼ì € ì„ íƒí•´ ì£¼ì„¸ìš”.")
                    continue

                saved_count = 0
                existing_ids = {a["article_id"] for a in st.session_state.saved_articles}
                edited_rows_by_id = {
                    row["_id"]: row.to_dict() for _, row in current_editor.iterrows()
                }
                for article in filtered_articles:
                    if article["id"] in selected_ids and article["id"] not in existing_ids:
                        edited_row = edited_rows_by_id.get(article["id"], {})
                        edited_press = str(edited_row.get("ì–¸ë¡ ì‚¬", article["press"])).strip()
                        final_press = (
                            normalize_press_name(edited_press, article["link"])
                            if edited_press
                            else normalize_press_name(article["press"], article["link"])
                        )
                        article["press"] = final_press
                        st.session_state.saved_articles.append(
                            {
                                "saved_id": str(uuid.uuid4())[:8],
                                "article_id": article["id"],
                                "folder": target_folder,
                                "saved_at": datetime.now(),
                                "title": article["title"],
                                "press": final_press,
                                "published_at": article["published_at"],
                                "link": article["link"],
                                "summary": article["summary"],
                                "negative_hits": article["negative_hits"],
                            }
                        )
                        saved_count += 1
                st.success(f"{saved_count}ê±´ì„ '{target_folder}' í´ë”ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")


def page_saved_db() -> None:
    st.title("ìŠ¤í¬ë© DB ë° í´ë” ê´€ë¦¬")
    st.caption("ì˜êµ¬ ì €ì¥ëœ ê¸°ì‚¬ì™€ í´ë”ë¥¼ ê´€ë¦¬í•˜ê³  ì—‘ì…€ë¡œ ë‚´ë³´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.subheader("í´ë” ê´€ë¦¬")
    add_col, delete_col = st.columns(2)
    with add_col:
        new_folder = st.text_input("ìƒˆ í´ë”ëª…")
        if st.button("í´ë” ì¶”ê°€"):
            cleaned_folder = new_folder.strip()
            if not cleaned_folder:
                st.warning("í´ë”ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            elif cleaned_folder in st.session_state.folders:
                st.warning("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í´ë”ì…ë‹ˆë‹¤.")
            else:
                st.session_state.folders.append(cleaned_folder)
                st.success(f"'{cleaned_folder}' í´ë”ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")

    with delete_col:
        removable_folders = st.multiselect("ì‚­ì œí•  í´ë”(ë‹¤ì¤‘ ì„ íƒ)", st.session_state.folders)
        delete_with_articles = st.checkbox("í•´ë‹¹ í´ë” ê¸°ì‚¬ë„ í•¨ê»˜ ì‚­ì œ", value=False)
        if st.button("ì„ íƒ í´ë” ì‚­ì œ"):
            if not removable_folders:
                st.warning("ì‚­ì œí•  í´ë”ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                if delete_with_articles:
                    st.session_state.saved_articles = [
                        s for s in st.session_state.saved_articles if s["folder"] not in removable_folders
                    ]
                else:
                    fallback_folder = "ë¯¸ë¶„ë¥˜"
                    if fallback_folder not in st.session_state.folders:
                        st.session_state.folders.append(fallback_folder)
                    for saved in st.session_state.saved_articles:
                        if saved["folder"] in removable_folders:
                            saved["folder"] = fallback_folder

                st.session_state.folders = [
                    f for f in st.session_state.folders if f not in removable_folders
                ]
                if not st.session_state.folders:
                    st.session_state.folders = ["ë¯¸ë¶„ë¥˜"]
                st.success(f"{len(removable_folders)}ê°œ í´ë”ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")

    st.divider()
    selected_folder = st.selectbox(
        "í´ë” í•„í„°",
        ["ì „ì²´"] + st.session_state.folders,
    )

    saved = st.session_state.saved_articles
    if selected_folder != "ì „ì²´":
        saved = [s for s in saved if s["folder"] == selected_folder]

    if not saved:
        st.info("ì €ì¥ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    display_df = pd.DataFrame(
        [
            {
                "ì„ íƒ": False,
                "í´ë”": s["folder"],
                "ê¸°ì‚¬ì œëª©": s["title"],
                "ì–¸ë¡ ì‚¬": normalize_press_name(s["press"], s["link"]),
                "ë°œí–‰ì¼ì‹œ": fmt_dt(s["published_at"]),
                "ì €ì¥ì¼ì‹œ": fmt_dt(s["saved_at"]),
                "ë¶€ì •í‚¤ì›Œë“œ": s["negative_hits"],
                "ë§í¬": s["link"],
                "_saved_id": s["saved_id"],
            }
            for s in sorted(saved, key=lambda x: x["saved_at"], reverse=True)
        ]
    )

    excel_export_df = display_df.drop(columns=["ì„ íƒ", "_saved_id"])
    excel_bytes = to_excel_bytes(excel_export_df, "Saved_DB")
    st.download_button(
        label="ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=excel_bytes,
        file_name=f"pr_radar_saved_db_{datetime.now().strftime('%Y%m%d')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

    edited_saved_df = st.data_editor(
        display_df,
        hide_index=True,
        use_container_width=True,
        disabled=["í´ë”", "ê¸°ì‚¬ì œëª©", "ì–¸ë¡ ì‚¬", "ë°œí–‰ì¼ì‹œ", "ì €ì¥ì¼ì‹œ", "ë¶€ì •í‚¤ì›Œë“œ", "ë§í¬", "_saved_id"],
        column_config={
            "_saved_id": None,
            "ì„ íƒ": st.column_config.CheckboxColumn("ì„ íƒ"),
            "ë§í¬": st.column_config.LinkColumn("ë§í¬"),
        },
        key="saved_db_editor",
    )

    if st.button("ì„ íƒí•œ ìŠ¤í¬ë© ê¸°ì‚¬ ì‚­ì œ", type="secondary"):
        selected_saved_ids = edited_saved_df.loc[edited_saved_df["ì„ íƒ"] == True, "_saved_id"].tolist()
        if not selected_saved_ids:
            st.warning("ì‚­ì œí•  ìŠ¤í¬ë© ê¸°ì‚¬ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        else:
            st.session_state.saved_articles = [
                s for s in st.session_state.saved_articles if s["saved_id"] not in selected_saved_ids
            ]
            st.success(f"{len(selected_saved_ids)}ê±´ì˜ ìŠ¤í¬ë© ê¸°ì‚¬ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")

    st.divider()
    st.subheader("ìˆ˜ì • ìš”ì²­ ë“±ë¡")
    options = {
        f"{s['title']} | {s['press']} | {fmt_dt(s['published_at'])}": s for s in saved
    }
    picked = st.selectbox("ìˆ˜ì • ìš”ì²­í•  ê¸°ì‚¬ ì„ íƒ", list(options.keys()))
    memo = st.text_input("ìˆ˜ì • ìš”ì²­ ë©”ëª¨", placeholder="ì˜ˆ: ì œëª© ë‚´ ì‚¬ì‹¤ì˜¤ë¥˜ ì •ì • ìš”ì²­")
    if st.button("ìˆ˜ì • ìš”ì²­ í•­ëª© ì¶”ê°€"):
        chosen = options[picked]
        st.session_state.correction_items.append(
            {
                "id": str(uuid.uuid4())[:8],
                "article_id": chosen["article_id"],
                "published_at": chosen["published_at"],
                "press": chosen["press"],
                "title": chosen["title"],
                "link": chosen["link"],
                "status": "ìš”ì²­ë¨",
                "memo": memo,
            }
        )
        st.success("ìˆ˜ì • ìš”ì²­ í•­ëª©ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")


def page_correction_tracking() -> None:
    st.title("ê¸°ì‚¬ ìˆ˜ì • ìš”ì²­ ê´€ë¦¬")
    st.caption("ìš”ì²­ ìƒíƒœì™€ ìˆ˜ì • ë‚´ìš© ë©”ëª¨ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")

    if not st.session_state.correction_items:
        st.info("ë“±ë¡ëœ ìˆ˜ì • ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    for idx, item in enumerate(
        sorted(st.session_state.correction_items, key=lambda x: x["published_at"], reverse=True)
    ):
        with st.container(border=True):
            c1, c2 = st.columns([1, 3])
            c1.write(f"**ë°œí–‰ì¼ì‹œ**  \n{fmt_dt(item['published_at'])}")
            c1.write(f"**ì–¸ë¡ ì‚¬**  \n{item['press']}")
            c2.markdown(f"**ê¸°ì‚¬ ì œëª©:** [{item['title']}]({item['link']})")

            status = st.radio(
                "ì§„í–‰ìƒíƒœ",
                ["ìš”ì²­ë¨", "ìˆ˜ì •ì™„ë£Œ", "í™•ì¸ë¶ˆê°€"],
                horizontal=True,
                index=["ìš”ì²­ë¨", "ìˆ˜ì •ì™„ë£Œ", "í™•ì¸ë¶ˆê°€"].index(item["status"]),
                key=f"status_{item['id']}_{idx}",
            )
            memo = st.text_input(
                "ìˆ˜ì • ë‚´ìš© ë©”ëª¨",
                value=item["memo"],
                key=f"memo_{item['id']}_{idx}",
            )

            item["status"] = status
            item["memo"] = memo

    df = pd.DataFrame(
        [
            {
                "ë°œí–‰ì¼ì‹œ": fmt_dt(i["published_at"]),
                "ì–¸ë¡ ì‚¬": i["press"],
                "ê¸°ì‚¬ì œëª©": i["title"],
                "ë§í¬": i["link"],
                "ì§„í–‰ìƒíƒœ": i["status"],
                "ìˆ˜ì •ë‚´ìš©ë©”ëª¨": i["memo"],
            }
            for i in st.session_state.correction_items
        ]
    )
    excel_bytes = to_excel_bytes(df, "Corrections")
    st.download_button(
        label="ìˆ˜ì • ìš”ì²­ ë‚´ì—­ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
        data=excel_bytes,
        file_name=f"pr_radar_corrections_{datetime.now().strftime('%Y%m%d')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )


def main() -> None:
    init_state()
    run_hourly_auto_collect()
    purge_old_inbox(days=7)
    refresh_alerts()

    page = draw_sidebar()
    if page == "ë©”ì¸ ëŒ€ì‹œë³´ë“œ":
        page_dashboard()
    elif page == "ì„ì‹œ ë³´ê´€í•¨ (Inbox)":
        page_inbox()
    elif page == "ìŠ¤í¬ë© DB ë° í´ë” ê´€ë¦¬":
        page_saved_db()
    elif page == "ê¸°ì‚¬ ìˆ˜ì • ìš”ì²­ ê´€ë¦¬":
        page_correction_tracking()


if __name__ == "__main__":
    main()
